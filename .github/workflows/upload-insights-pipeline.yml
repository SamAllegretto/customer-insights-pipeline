name: Upload Scripts to Azure Storage

on:
  push:
    branches: [ main, develop ]
    paths: 
      - 'src/**'
      - 'tests/**'
      - 'requirements.txt'
      - 'requirements-dev.txt'
      - 'setup.py'
      - '.github/workflows/upload-insights-pipeline.yml'
  
  workflow_dispatch:
    inputs:
      force_upload:
        description: 'Force upload all scripts'
        required: false
        default: true
        type: boolean

env:
  PYTHON_VERSION: '3.11'

jobs:
  validate:
    name: Validate All Scripts
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies from requirements file
      run: |
        python -m pip install --upgrade pip
        pip install flake8
        
        # Install from requirements.txt
        if [ -f requirements.txt ]; then
          echo "ğŸ“¦ Installing dependencies from requirements.txt"
          pip install -r requirements.txt
        else
          echo "ğŸ“¦ Installing basic dependencies for validation"
          pip install pandas numpy requests azure-storage-blob azure-batch
        fi
    
    - name: Lint all scripts
      run: |
        echo "ğŸ” Validating all Python scripts..."
        
        # Find and lint all Python files
        find . -name "*.py" -not -path "./.git/*" -not -path "./.*" | \
        xargs flake8 --count --select=E9,F63,F7,F82 --show-source --statistics
        
        echo "âœ… Basic syntax validation passed"
    
    - name: List all scripts to be uploaded
      run: |
        echo "ğŸ“‹ Scripts that will be uploaded:"
        echo "================================"
        
        echo "ğŸ“‚ Source Scripts:"
        find src/ -name "*.py" 2>/dev/null | sort || echo "  No src scripts found"
        
        echo "ğŸ§ª Test Scripts:"
        find tests/ -name "*.py" 2>/dev/null | sort || echo "  No test scripts found"
    
    - name: Check requirements files
      run: |
        echo "ğŸ“‹ Checking requirements files..."
        
        if [ -f requirements.txt ]; then
          echo "âœ… Found requirements.txt:"
          cat requirements.txt
        fi
        
        if [ -f requirements-dev.txt ]; then
          echo "âœ… Found requirements-dev.txt:"
          cat requirements-dev.txt
        fi
        
        if [ ! -f requirements.txt ]; then
          echo "âš ï¸  No requirements.txt file found. Consider creating one."
        fi

  upload-scripts:
    name: Upload All Scripts to Azure Storage
    runs-on: ubuntu-latest
    needs: validate
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install Azure CLI and dependencies
      run: |
        curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash
        python -m pip install --upgrade pip
        pip install azure-storage-blob azure-identity
    
    - name: Azure Login
      uses: azure/login@v1
      with:
        creds: ${{ secrets.AZURE_CREDENTIALS }}
        enable-AzPSSession: false
    
    - name: Verify Azure Login
      run: |
        echo "ğŸ” Verifying Azure login..."
        az account show --output table
        echo "âœ… Azure login successful"
    
    - name: Ensure required containers exist
      run: |
        echo "ğŸ“¦ Ensuring required storage containers exist..."
        
        # Function to create container if it doesn't exist
        create_container_if_not_exists() {
          local container_name=$1
          
          echo "ğŸ” Checking if container '$container_name' exists..."
          
          # Try to create the container using auth-mode login
          if az storage container create \
            --name $container_name \
            --account-name ${{ secrets.AZURE_STORAGE_ACCOUNT }} \
            --auth-mode login \
            --output none 2>/dev/null; then
            echo "  âœ… Created '$container_name' container"
          else
            # Container might already exist, let's check
            if az storage container show \
              --name $container_name \
              --account-name ${{ secrets.AZURE_STORAGE_ACCOUNT }} \
              --auth-mode login \
              --output none 2>/dev/null; then
              echo "  âœ… '$container_name' container already exists"
            else
              echo "  âŒ Failed to create or verify '$container_name' container"
              exit 1
            fi
          fi
        }
        
        # Create required containers
        create_container_if_not_exists "customer-insights-pipeline"
        
        echo "ğŸ“¦ All required containers are ready!"
    
    - name: Upload src scripts
      run: |
        echo "ğŸ“‚ Uploading src scripts..."
        
        if [ -d "src" ]; then
          # Upload each Python file in src folder
          find src/ -name "*.py" | while read -r file; do
            if [ -f "$file" ]; then
              # Get relative path from src/ folder
              relative_path=${file#src/}
              blob_name="src/$relative_path"
              
              echo "ğŸ“¤ Uploading $blob_name..."
              az storage blob upload \
                --account-name ${{ secrets.AZURE_STORAGE_ACCOUNT }} \
                --container-name customer-insights-pipeline \
                --name "$blob_name" \
                --file "$file" \
                --overwrite \
                --auth-mode login
              
              echo "  âœ… Uploaded $blob_name"
            fi
          done
        else
          echo "  âš ï¸ No src folder found"
        fi
    
    - name: Upload test scripts
      run: |
        echo "ğŸ§ª Uploading test scripts..."
        
        if [ -d "tests" ]; then
          find tests/ -name "*.py" | while read -r file; do
            if [ -f "$file" ]; then
              relative_path=${file#tests/}
              blob_name="tests/$relative_path"
              
              echo "ğŸ“¤ Uploading $blob_name..."
              az storage blob upload \
                --account-name ${{ secrets.AZURE_STORAGE_ACCOUNT }} \
                --container-name customer-insights-pipeline \
                --name "$blob_name" \
                --file "$file" \
                --overwrite \
                --auth-mode login
              
              echo "  âœ… Uploaded $blob_name"
            fi
          done
        else
          echo "  âš ï¸ No tests folder found"
        fi
    
    - name: Upload setup.py
      run: |
        echo "âš™ï¸ Uploading setup.py..."
        
        if [ -f "setup.py" ]; then
          az storage blob upload \
            --account-name ${{ secrets.AZURE_STORAGE_ACCOUNT }} \
            --container-name customer-insights-pipeline \
            --name "setup.py" \
            --file "setup.py" \
            --overwrite \
            --auth-mode login
          echo "  âœ… Uploaded setup.py"
        else
          echo "  âš ï¸ No setup.py found"
        fi
    
    - name: Upload requirements files
      run: |
        echo "ğŸ“¤ Uploading requirements files..."
        
        # Upload requirements.txt for easy access by ADF
        if [ -f "requirements.txt" ]; then
          az storage blob upload \
            --account-name ${{ secrets.AZURE_STORAGE_ACCOUNT }} \
            --container-name customer-insights-pipeline \
            --name "requirements.txt" \
            --file "requirements.txt" \
            --overwrite \
            --auth-mode login
          echo "  âœ… Uploaded requirements.txt"
        else
          echo "  âš ï¸  No requirements.txt file found to upload"
        fi
        
        # Upload requirements-dev.txt
        if [ -f "requirements-dev.txt" ]; then
          az storage blob upload \
            --account-name ${{ secrets.AZURE_STORAGE_ACCOUNT }} \
            --container-name customer-insights-pipeline \
            --name "requirements-dev.txt" \
            --file "requirements-dev.txt" \
            --overwrite \
            --auth-mode login
          echo "  âœ… Uploaded requirements-dev.txt"
        else
          echo "  âš ï¸  No requirements-dev.txt file found to upload"
        fi
    
    - name: Create script inventory
      run: |
        echo "ğŸ“‹ Creating script inventory for ADF..."
        
        # Create timestamp for versioning
        TIMESTAMP=$(date +%Y%m%d-%H%M%S)
        COMMIT_SHA=${GITHUB_SHA:0:7}
        VERSION="${TIMESTAMP}-${COMMIT_SHA}"
        
        # Determine requirements file location
        REQ_FILE_LOCATION="none"
        if [ -f "requirements.txt" ]; then
          REQ_FILE_LOCATION="requirements.txt"
        fi
        
        # Create a JSON inventory of all available scripts
        cat > script_inventory.json << EOF
        {
          "version": "$VERSION",
          "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
          "commit_sha": "${GITHUB_SHA}",
          "requirements_file": "$REQ_FILE_LOCATION",
          "upload_type": "individual_files",
          "storage_structure": {
            "base_url": "https://${{ secrets.AZURE_STORAGE_ACCOUNT }}.blob.core.windows.net/customer-insights-pipeline",
            "folders": {
              "src": "src/",
              "tests": "tests/"
            }
          },
          "modules": {
            "agents": {
              "folder": "src/agents",
              "scripts": $(find src/agents/ -name "*.py" 2>/dev/null | sed 's|src/agents/||' | sed 's|\.py$||' | jq -R . | jq -s . || echo '[]')
            },
            "clustering": {
              "folder": "src/clustering",
              "scripts": $(find src/clustering/ -name "*.py" 2>/dev/null | sed 's|src/clustering/||' | sed 's|\.py$||' | jq -R . | jq -s . || echo '[]')
            },
            "config": {
              "folder": "src/config",
              "scripts": $(find src/config/ -name "*.py" 2>/dev/null | sed 's|src/config/||' | sed 's|\.py$||' | jq -R . | jq -s . || echo '[]')
            },
            "data_access": {
              "folder": "src/data_access",
              "scripts": $(find src/data_access/ -name "*.py" 2>/dev/null | sed 's|src/data_access/||' | sed 's|\.py$||' | jq -R . | jq -s . || echo '[]')
            },
            "embedding": {
              "folder": "src/embedding",
              "scripts": $(find src/embedding/ -name "*.py" 2>/dev/null | sed 's|src/embedding/||' | sed 's|\.py$||' | jq -R . | jq -s . || echo '[]')
            },
            "models": {
              "folder": "src/models",
              "scripts": $(find src/models/ -name "*.py" 2>/dev/null | sed 's|src/models/||' | sed 's|\.py$||' | jq -R . | jq -s . || echo '[]')
            },
            "pipelines": {
              "folder": "src/pipelines",
              "scripts": $(find src/pipelines/ -name "*.py" 2>/dev/null | sed 's|src/pipelines/||' | sed 's|\.py$||' | jq -R . | jq -s . || echo '[]')
            }
          },
          "tests": $(find tests/ -name "*.py" 2>/dev/null | sed 's|tests/||' | sed 's|\.py$||' | jq -R . | jq -s . || echo '[]')
        }
        EOF
        
        echo "ğŸ“‹ Script inventory created:"
        cat script_inventory.json | jq .
    
    - name: Upload script inventory
      run: |
        echo "ğŸ“¤ Uploading script inventory..."
        
        az storage blob upload \
          --account-name ${{ secrets.AZURE_STORAGE_ACCOUNT }} \
          --container-name customer-insights-pipeline \
          --name "inventory/script_inventory.json" \
          --file "script_inventory.json" \
          --overwrite \
          --auth-mode login
        
        echo "âœ… Script inventory uploaded"
    
    - name: List uploaded files
      run: |
        echo "ğŸ“‹ Listing all uploaded files in storage..."
        az storage blob list \
          --account-name ${{ secrets.AZURE_STORAGE_ACCOUNT }} \
          --container-name customer-insights-pipeline \
          --auth-mode login \
          --output table \
          --query "[].{Name:name, Size:properties.contentLength, LastModified:properties.lastModified}"
    
    - name: Summary
      run: |
        echo "ğŸ‰ Script upload completed successfully!"
        echo "=================================="
        echo "ğŸ“ Scripts uploaded as individual files to:"
        echo "  â€¢ src/ folder (agents, clustering, config, data_access, embedding, models, pipelines)"
        echo "  â€¢ tests/ folder"
        echo "  â€¢ setup.py"
        echo ""
        echo "ğŸ“‹ Script inventory: inventory/script_inventory.json"
        echo "ğŸ“‹ Requirements files: requirements.txt, requirements-dev.txt"
        echo "ğŸ”— Storage URL: https://${{ secrets.AZURE_STORAGE_ACCOUNT }}.blob.core.windows.net/customer-insights-pipeline/"
        echo ""
        echo "ğŸ¯ Individual files can now be accessed directly in Azure Data Factory!"

  notify:
    name: Notify Upload Status
    runs-on: ubuntu-latest
    needs: [validate, upload-scripts]
    if: always()
    
    steps:
    - name: Upload Status
      run: |
        if [ "${{ needs.upload-scripts.result }}" == "success" ]; then
          echo "âœ… All scripts uploaded successfully to Azure Storage!"
          echo "ğŸ¯ Ready for use in Azure Data Factory pipelines"
          echo "ğŸ“ Storage Account: ${{ secrets.AZURE_STORAGE_ACCOUNT }}"
          echo "ğŸ“ Container: customer-insights-pipeline/"
          echo "ğŸ“ Files are organized in folders by data source"
        else
          echo "âŒ Script upload failed!"
          echo "ğŸ“‹ Check the logs above for details"
        fi